{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corresponding-judge",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kplam624/Mask-Finder/blob/imagepreprocessing/image_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driven-disposal",
   "metadata": {
    "id": "driven-disposal"
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import (\n",
    "    VGG19,\n",
    "    preprocess_input,\n",
    "    decode_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alone-stupid",
   "metadata": {
    "id": "alone-stupid"
   },
   "outputs": [],
   "source": [
    "names = ['with_mask', 'without_mask']\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-artwork",
   "metadata": {},
   "source": [
    "# Code if run on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gAAJggUBAnag",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAAJggUBAnag",
    "outputId": "7a6626c2-0cf0-40e7-a3b9-c9c0a55b14e6"
   },
   "outputs": [],
   "source": [
    "# When Running on google colab use the following to install the split-folders library\n",
    "# !pip install split-folders \n",
    "# import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rqCNe6LrxqpX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqCNe6LrxqpX",
    "outputId": "58ce7f2e-03c2-408e-fd85-9c2063765212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aDUFoiLEyRvB",
   "metadata": {
    "id": "aDUFoiLEyRvB"
   },
   "outputs": [],
   "source": [
    "Data = '/content/drive/MyDrive/Colab Notebooks/maskfinder/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5sUTKYs_BNDD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sUTKYs_BNDD",
    "outputId": "6f6f6331-83ba-4d89-953c-9645e480f8c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 11043 files [26:32,  6.93 files/s]\n"
     ]
    }
   ],
   "source": [
    "# Line below will split the folders into test, validation, and test data.\n",
    "# Only run when first using the notebook!!\n",
    "\n",
    "# splitfolders.ratio(Data, output=\"output\", seed=1337, ratio=(.8, 0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "MlMZDxGlIG4h",
   "metadata": {
    "id": "MlMZDxGlIG4h"
   },
   "outputs": [],
   "source": [
    "# Define what the train, test, and validation datasets are.\n",
    "train_data = '/content/output/train'\n",
    "test_data = '/content/output/test'\n",
    "val_data = '/content/output/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-latter",
   "metadata": {},
   "source": [
    "# If Running on a jupyter notebook run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "buried-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "killing-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = 'Data'\n",
    "splitfolders.ratio(Data, output = \"output\", seed = 1337, ratio=(.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finnish-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what the train, test, and validation datasets are.\n",
    "train_data = 'output/train'\n",
    "test_data = 'output/test'\n",
    "val_data = 'output/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-consent",
   "metadata": {},
   "source": [
    "## The training is the same whether for colab or for Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focal-vampire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "focal-vampire",
    "outputId": "b96ba288-2060-4d22-b48b-cbac0936d26a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator at 0x7f79dd74c850>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True)\n",
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6g3IKxRfJS8K",
   "metadata": {
    "id": "6g3IKxRfJS8K"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "perceived-address",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "perceived-address",
    "outputId": "e305076f-62a7-4424-eb67-6562c5bd3376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8833 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = train_data,\n",
    "    target_size = (220,220),\n",
    "    batch_size = batch,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "confused-reform",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "confused-reform",
    "outputId": "628e39f5-fcfd-4b97-f555-53aa045dc768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1104 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    directory = val_data,\n",
    "    target_size = (220,220),\n",
    "    batch_size = batch,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "related-playback",
   "metadata": {
    "id": "related-playback"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facial-visit",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "facial-visit",
    "outputId": "d7e171fb-5030-45c5-b11a-9a8013ba9b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights = \"imagenet\", include_top = False, input_shape = (220,220,3))\n",
    "\n",
    "for layers in vgg19.layers:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ordered-detail",
   "metadata": {
    "id": "ordered-detail"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collectible-blade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "collectible-blade",
    "outputId": "e87e1f18-4b46-44f1-fc21-1479f23b8525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 6, 6, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 20,061,250\n",
      "Trainable params: 36,866\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "special-bumper",
   "metadata": {
    "id": "special-bumper"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graphic-stress",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "graphic-stress",
    "outputId": "e935d64b-3973-4ca7-99f9-10724b90bfd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 213s 27s/step - loss: 0.8881 - accuracy: 0.6562 - val_loss: 0.3159 - val_accuracy: 0.8594\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 206s 26s/step - loss: 0.4243 - accuracy: 0.8594 - val_loss: 0.1097 - val_accuracy: 0.9844\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 205s 26s/step - loss: 0.2466 - accuracy: 0.9141 - val_loss: 0.0709 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 203s 25s/step - loss: 0.2242 - accuracy: 0.9219 - val_loss: 0.0870 - val_accuracy: 0.9688\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 204s 26s/step - loss: 0.1807 - accuracy: 0.9414 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 202s 25s/step - loss: 0.1543 - accuracy: 0.9492 - val_loss: 0.1132 - val_accuracy: 0.9531\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 202s 25s/step - loss: 0.1408 - accuracy: 0.9375 - val_loss: 0.0372 - val_accuracy: 0.9844\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 202s 25s/step - loss: 0.1027 - accuracy: 0.9648 - val_loss: 0.1507 - val_accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 202s 25s/step - loss: 0.0753 - accuracy: 0.9727 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 202s 25s/step - loss: 0.1120 - accuracy: 0.9688 - val_loss: 0.0337 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# This is to further train the model.\n",
    "# Keep in mind that to further train the model, a strong processor/ computing power is needed.\n",
    "# A common error that occurs is 'UnidentifiedImageError'\n",
    "# Try in google colab and if the error still occurs, you do not have the processing power for the size of the data.\n",
    "model.fit(train_generator,\n",
    "            steps_per_epoch = len(train_generator)//32,\n",
    "            epochs = 10,\n",
    "            validation_data = test_generator,\n",
    "            validation_steps=len(test_generator)//32,\n",
    "            verbose = 1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-defensive",
   "metadata": {
    "id": "sufficient-defensive"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "image_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
