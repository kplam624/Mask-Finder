{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bound-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from numpy import asarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polished-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and read image\n",
    "images_dir = cv2.imread(\"/Users/atemkuh/Documents/GitHub/Mask-Finder/dataset/with_mask/0_0_≈˙◊¢ 2020-02-23 132115.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sudden-lucas",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-40fplvaz/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cbd1e6ce043a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#view image and convert into RGB using cv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-40fplvaz/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#view image and convert into RGB using cv2\n",
    "plt.imshow(cv2.cvtColor(images_dir, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stopped-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_dir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through dataset\n",
    "Images_directory = \"/Users/atemkuh/Documents/GitHub/Mask-Finder/dataset\"\n",
    "Classes = [\"with_mask\",\"without_mask\"]\n",
    "for category in Classes:\n",
    "    path = os.path.join(Images_directory, category)\n",
    "    for img in os.listdir(path):\n",
    "        images_dir = cv2.imread(os.path.join(path,img))\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(images_dir, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        # stop processing after first image\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images using imageNet \n",
    "img_size = 224\n",
    "new_img_array=cv2.resize(images_dir,(img_size,img_size))\n",
    "plt.imshow(cv2.cvtColor(images_dir, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to arrays \n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in Classes:\n",
    "        path = os.path.join(Images_directory,category)\n",
    "        class_num = Classes.index(category)\n",
    "        \n",
    "        print(\"category\")\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "               # print(img, \", \", path)\n",
    "                images_dir    = cv2.imread(os.path.join(path,img))\n",
    "                \n",
    "                new_img_array = cv2.resize(images_dir,(img_size,img_size))\n",
    "                \n",
    "                training_data.append([new_img_array, class_num])\n",
    "              #  print(len(training_data))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "y=[]\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1,img_size,img_size,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle x\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "#pickle y\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serious-carroll",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d46d7144e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create and train deep learning model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#pre trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Total params: 4,253,864\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#create and train deep learning model\n",
    "#pre trained model\n",
    "model = tf.keras.applications.MobileNet()\n",
    "model.summary() #Total params: 4,253,864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing solution by implementing transfer learning \"tuning\", \"weights\"\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[-4].output\n",
    "Flatten_layer =  layers.Flatten()(base_output)\n",
    "#classifier  can either be 0 or 1\n",
    "final_output = layers.Dense(1)(Flatten_layer)\n",
    "final_output = layers.Activation('sigmoid')(final_output)\n",
    "#new model\n",
    "\n",
    "new_model=keras.Model(inputs = base_input, outputs = final_output)\n",
    "new_model.summary()## display the sum of the new model #Total params: 3,229,889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup up configuration os classes('with_mask','without_mask')\n",
    "\n",
    "#compile new model\n",
    "new_model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit (X,Y, epochs = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "frame = cv2.imread('demo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img =cv2.resize(frame,(224,224))\n",
    "final_img =np.expand_dims(final_img, axis=0)\n",
    "final_img = final_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = new_model.predict(final_img)\n",
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Haar feature detector\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "#convert image from BGR to gray\n",
    "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "gray"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
